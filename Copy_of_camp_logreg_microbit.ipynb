{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Harris512/AI_Cyberinfrastructure_work/blob/main/Copy_of_camp_logreg_microbit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8zEKfKdxR48"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/cyneuro/ML_camp/blob/main/camp_logreg_microbit.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2i8ieYYxxR49"
      },
      "source": [
        "# Logistic regression with micro:bit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3y6yjzQxR4-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.integrate import cumulative_trapezoid\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6H-jwRRQfvj"
      },
      "source": [
        "## 1. Read and preprocess the data\n",
        "\n",
        "- Read the recorded dataset.\n",
        "- Compute velocity and position from acceleration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1S7T-ahxR4-"
      },
      "outputs": [],
      "source": [
        "# Convert milligravities to m/s2\n",
        "MG_TO_MS2 = 0.00980665\n",
        "\n",
        "def process_data(data):\n",
        "    # Clean the columns\n",
        "    orig_columns = [\"time (seconds)\", \"x\", \"y\", \"z\"]\n",
        "    new_columns = [\"t\", \"ax\", \"ay\", \"az\"]\n",
        "    data = data[orig_columns]\n",
        "    data.columns = new_columns\n",
        "\n",
        "    # Clean NaNs\n",
        "    data = data.dropna()\n",
        "\n",
        "    # Convert to m/s2\n",
        "    for acc in ['ax', 'ay', 'az']:\n",
        "        data[acc] = data[acc] * MG_TO_MS2\n",
        "\n",
        "    # Replace outliers with the median\n",
        "    for acc in ['ax', 'ay', 'az']:\n",
        "        acc_raw = data[acc].copy()\n",
        "        acc_raw[np.abs(acc_raw / np.median(acc_raw)) > 1.5] = np.median(acc_raw)\n",
        "        data[acc] = acc_raw\n",
        "\n",
        "    # Compute velocity\n",
        "    data['vx'] = cumulative_trapezoid(data['ax'], data['t'], initial = 0)\n",
        "    data['vy'] = cumulative_trapezoid(data['ay'], data['t'], initial = 0)\n",
        "    data['vz'] = cumulative_trapezoid(data['az'], data['t'], initial = 0)\n",
        "\n",
        "    # Compute position\n",
        "    data['x'] = cumulative_trapezoid(data['vx'], data['t'], initial = 0)\n",
        "    data['y'] = cumulative_trapezoid(data['vy'], data['t'], initial = 0)\n",
        "    data['z'] = cumulative_trapezoid(data['vz'], data['t'], initial = 0)\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_YPz9YOhxR4_"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"shake_data.csv\")\n",
        "data = process_data(data)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9L01wjBxR5A"
      },
      "outputs": [],
      "source": [
        "for acc in ['ax', 'ay', 'az']:\n",
        "    plt.plot(data['t'], data[acc], label = acc)\n",
        "plt.xlabel(\"time (s)\")\n",
        "plt.ylabel(\"acceleration (m/s2)\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d29a_bb_Qfvl"
      },
      "source": [
        "## 2. Split into train and test samples.\n",
        "- Train: the first shake.\n",
        "- Test: the second shake."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDz7m2jGQfvl"
      },
      "outputs": [],
      "source": [
        "train_rest = (14.0, 17.5) # (seconds)\n",
        "train_shake = (18.0, 23.0) # (seconds)\n",
        "\n",
        "test_rest = (23.0, 27.0) # (seconds)\n",
        "test_shake = (28.0, 32.0) # (seconds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qr-cfXprQfvl"
      },
      "outputs": [],
      "source": [
        "def construct_Xy(data, window_rest, window_shake):\n",
        "    X = pd.concat((\n",
        "        data.loc[(data['t'] >= window_rest[0]) & (data['t'] <= window_rest[1]), ['t', 'ax', 'ay', 'az']],\n",
        "        data.loc[(data['t'] >= window_shake[0]) & (data['t'] <= window_shake[1]), ['t', 'ax', 'ay', 'az']],\n",
        "    ))\n",
        "    y = np.ones(len(X))\n",
        "    y[(X['t'] >= window_rest[0]) & (X['t'] <= window_rest[1])] = 0\n",
        "\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kn_w4oy5Qfvm"
      },
      "outputs": [],
      "source": [
        "X_train, y_train = construct_Xy(data, train_rest, train_shake)\n",
        "X_test, y_test = construct_Xy(data, test_rest, test_shake)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTh_yyWbQfvm"
      },
      "outputs": [],
      "source": [
        "plt.plot(X_train['t'], X_train[\"az\"], label = \"Train\")\n",
        "plt.plot(X_test['t'], X_test[\"az\"], label = \"Test\")\n",
        "\n",
        "label_set = False\n",
        "for X, y in [(X_train, y_train), (X_test, y_test)]:\n",
        "    for y_value, y_label in enumerate([\"Rest\", \"Shake\"]):\n",
        "        plt.axvspan(\n",
        "            X['t'].to_numpy()[np.where(y == y_value)[0][0]],\n",
        "            X['t'].to_numpy()[np.where(y == y_value)[0][-1]],\n",
        "            alpha = 0.3,\n",
        "            color = \"tab:green\" if y_value == 0 else \"tab:red\",\n",
        "            label = y_label if not label_set else None\n",
        "            )\n",
        "    label_set = True\n",
        "\n",
        "plt.xlabel(\"time (s)\")\n",
        "plt.ylabel(\"z-acceleration (m/s2)\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBkUvmqaQfvm"
      },
      "source": [
        "## 3. Train a logistic regression model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsGywDu9xR5B"
      },
      "source": [
        "Compare 2 models.\n",
        "\n",
        "**Model 1.**\n",
        "\n",
        "$$\n",
        "\\hat{p} = \\sigma(b_0 + b_t \\times t + b_x \\times a_x + b_y \\times a_y + b_z \\times a_z)\n",
        "$$\n",
        "\n",
        "**Model 2.**\n",
        "\n",
        "$$\n",
        "\\hat{p} = \\sigma(b_0 + b_x \\times a_x + b_y \\times a_y + b_z \\times a_z)\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9t4QhmBpQfvm"
      },
      "outputs": [],
      "source": [
        "model1 = LogisticRegression()\n",
        "model1.fit(X_train[[\"t\", \"ax\", \"ay\", \"az\"]], y_train)\n",
        "\n",
        "model2 = LogisticRegression()\n",
        "model2.fit(X_train[[\"ax\", \"ay\", \"az\"]], y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GeZHEz8jQfvn"
      },
      "outputs": [],
      "source": [
        "print(\"ACCURACY\")\n",
        "print(\"--------\")\n",
        "print(\"Model\\tTrain\\tTest\")\n",
        "for model_id, (model, features) in enumerate((\n",
        "    (model1, [\"t\", \"ax\", \"ay\", \"az\"]),\n",
        "    (model2, [\"ax\", \"ay\", \"az\"])\n",
        "    )):\n",
        "    train_acc = round(accuracy_score(y_train, model.predict(X_train[features])), 2)\n",
        "    test_acc = round(accuracy_score(y_test, model.predict(X_test[features])), 2)\n",
        "    print(f\"M{model_id}\\t{train_acc}\\t{test_acc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1XaLzr2KQfvn"
      },
      "outputs": [],
      "source": [
        "model1.predict(X_test[[\"t\", \"ax\", \"ay\", \"az\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpgxOXyPxR5C"
      },
      "outputs": [],
      "source": [
        "model2.predict(X_test[[\"ax\", \"ay\", \"az\"]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCIgeNGjQfvn"
      },
      "source": [
        "### Question\n",
        "\n",
        "Explain the observed difference between predictions of the two models.\n",
        "\n",
        "**Hint: compare the decision lines.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J0hzfVvlQfvn"
      },
      "outputs": [],
      "source": [
        "print(f\"Model1: intercept = {model1.intercept_}, coef = {model1.coef_}\")\n",
        "print(f\"Model2: intercept = {model2.intercept_}, coef = {model2.coef_}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Meuq7VRTQfvo"
      },
      "outputs": [],
      "source": [
        "plt.scatter(X_test[\"t\"], y_test)\n",
        "plt.xlabel(\"X[t]\")\n",
        "plt.ylabel(\"Target label\")\n",
        "\n",
        "plt.plot(X_test[\"t\"], model1.predict_proba(X_test[[\"t\", \"ax\", \"ay\", \"az\"]])[:, 1], label = \"Predicted probability\", c = \"black\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hD4Px-sdQfvo"
      },
      "outputs": [],
      "source": [
        "plt.scatter(X_test[\"az\"], y_test)\n",
        "plt.xlabel(\"X[az]\")\n",
        "plt.ylabel(\"Target label\")\n",
        "\n",
        "plt.plot(X_test.sort_values(\"az\")[\"az\"], model2.predict_proba(X_test.sort_values(\"az\")[[\"ax\", \"ay\", \"az\"]])[:, 1], label = \"Predicted probability\", c = \"black\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vtyhPQdbVwn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac76db75"
      },
      "source": [
        "# Task\n",
        "Perform an automated machine learning model comparison using LazyPredict to evaluate different classification models on the provided shake detection sensor data from `shake_data.csv`, using `X_train`, `X_test`, `y_train`, and `y_test` datasets, analyze their performance, and discuss their suitability for the problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "420c651b"
      },
      "source": [
        "## Install LazyPredict\n",
        "\n",
        "### Subtask:\n",
        "Install the `lazypredict` library, which is required for automated machine learning model comparison.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7612c3a"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask is to install the `lazypredict` library. The `pip install` command is used for this purpose.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8987bc3b"
      },
      "source": [
        "pip install lazypredict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54211253"
      },
      "source": [
        "## Run LazyPredict Models\n",
        "\n",
        "### Subtask:\n",
        "Utilize `LazyClassifier` from `lazypredict` to train and evaluate various classification models on the `X_train`, `X_test`, `y_train`, and `y_test` datasets.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dae795de"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires importing `LazyClassifier` and `accuracy_score`, preparing the feature dataframes by selecting only acceleration columns, initializing `LazyClassifier` with the specified parameters, and then fitting it to the training and test data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fb9ee75d"
      },
      "source": [
        "from lazypredict.Supervised import LazyClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Create new DataFrames with only acceleration columns\n",
        "X_train_acc = X_train[['ax', 'ay', 'az']]\n",
        "X_test_acc = X_test[['ax', 'ay', 'az']]\n",
        "\n",
        "# Initialize LazyClassifier\n",
        "clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=accuracy_score)\n",
        "\n",
        "# Fit LazyClassifier\n",
        "models, predictions = clf.fit(X_train_acc, X_test_acc, y_train, y_test)\n",
        "\n",
        "print(\"LazyClassifier models and predictions generated.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e841f753"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask of running LazyPredict models has been completed. Now, to analyze the performance of the various models, it is necessary to display the `models` DataFrame, which contains the evaluation metrics for each classifier.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fb54c3f"
      },
      "source": [
        "print(models)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1b33ecc"
      },
      "source": [
        "### Analysis of LazyPredict Models\n",
        "\n",
        "Based on the LazyClassifier results, the following observations can be made:\n",
        "\n",
        "*   **LGBMClassifier** stands out as the best-performing model with an **Accuracy, Balanced Accuracy, ROC AUC, and F1 Score of 0.91**. It also has a relatively fast training time of 0.09 seconds.\n",
        "*   **XGBClassifier** is the second-best model, showing strong performance with an **Accuracy, Balanced Accuracy, and ROC AUC of 0.82-0.83**.\n",
        "*   Many other models, including `BaggingClassifier`, `DummyClassifier`, `DecisionTreeClassifier`, `AdaBoostClassifier`, `RandomForestClassifier`, `Perceptron`, `LinearSVC`, `CalibratedClassifierCV`, `ExtraTreesClassifier`, `SVC`, `NuSVC`, `LogisticRegression`, `LabelPropagation`, `ExtraTreeClassifier`, and `LabelSpreading`, performed significantly worse, with accuracy scores around 0.50 or lower. This suggests they struggle to differentiate between 'rest' and 'shake' states given the current feature set.\n",
        "*   Models like `GaussianNB`, `QuadraticDiscriminantAnalysis`, `RidgeClassifierCV`, `SGDClassifier`, `LinearDiscriminantAnalysis`, `RidgeClassifier`, and `NearestCentroid` performed poorly, indicating their unsuitability for this particular dataset and problem with the current features.\n",
        "\n",
        "**Suitability for the problem:**\n",
        "\n",
        "Given the high accuracy and fast training time, **LGBMClassifier** appears to be the most suitable model for detecting shakes from the acceleration data. **XGBClassifier** is also a strong contender. The lower-performing models indicate that more complex or ensemble methods are likely required, or that additional feature engineering could be beneficial for simpler models to perform better. The original `LogisticRegression` model, which was manually trained, showed an accuracy of 0.31 on the test set (Model 2, using only acceleration features), which is consistent with the `LazyClassifier` result for `LogisticRegression` (0.49 accuracy), both indicating its limited capability for this specific shake detection task without further optimization or feature engineering."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a82d7bc8"
      },
      "source": [
        "## Discuss Model Suitability\n",
        "\n",
        "### Subtask:\n",
        "Analyze the results generated by LazyPredict, focusing on key performance metrics like accuracy. Based on these results and the characteristics of the dataset (sensor data for shake detection), discuss why certain models performed better than others and their suitability for this specific problem.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ca264e4f"
      },
      "source": [
        "## Discuss Model Suitability\n",
        "\n",
        "### Subtask:\n",
        "Analyze the results generated by LazyPredict, focusing on key performance metrics like accuracy. Based on these results and the characteristics of the dataset (sensor data for shake detection), discuss why certain models performed better than others and their suitability for this specific problem.\n",
        "\n",
        "#### Instructions\n",
        "1. Review the `models` DataFrame generated by LazyPredict, which contains performance metrics such as Accuracy, Balanced Accuracy, ROC AUC, F1 Score, and Time Taken for each classification model.\n",
        "2. Identify the top-performing models based on their accuracy and other relevant metrics. Note their performance scores and training times.\n",
        "3. Discuss potential reasons why the top-performing models (e.g., LGBMClassifier, XGBClassifier) achieved better results compared to others, considering that the data is from motion sensors for shake detection. Think about their strengths in handling this type of data.\n",
        "4. Analyze why many other models performed poorly (e.g., around 0.50 accuracy or lower), linking it to their inherent characteristics or limitations for this specific classification task with the given features.\n",
        "5. Conclude by summarizing which models are most suitable for the shake detection problem based on the observed performance and why, also noting if any models were particularly unsuitable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57d50f20"
      },
      "source": [
        "### LazyPredict Model Suitability Analysis\n",
        "\n",
        "Based on the `models` DataFrame generated by LazyPredict, we can analyze the performance of various classification models for shake detection:\n",
        "\n",
        "**1. Top-Performing Models:**\n",
        "\n",
        "*   **LGBMClassifier:** Achieved the highest accuracy of **0.91** with a relatively quick training time of 0.09 seconds. This indicates excellent performance in distinguishing between 'rest' and 'shake' states.\n",
        "*   **XGBClassifier:** Followed closely with an accuracy of **0.82** and a training time of 0.11 seconds. Also a strong performer.\n",
        "\n",
        "These models, both gradient boosting frameworks, demonstrate superior performance for this task. Their ensemble nature and ability to model complex, non-linear relationships present in sensor data (accelerometer readings) likely contribute to their success. They are robust to noisy data and can effectively learn intricate patterns from time-series-like sensor signals, even when only static acceleration features are provided for each time point.\n",
        "\n",
        "**2. Models with Moderate to Poor Performance:**\n",
        "\n",
        "Many other models, including `BaggingClassifier`, `DecisionTreeClassifier`, `AdaBoostClassifier`, `RandomForestClassifier`, `Perceptron`, `LinearSVC`, `CalibratedClassifierCV`, `LogisticRegression`, `SVC`, and others, showed accuracy scores ranging from **0.59 down to 0.26**. Notably, a large number of models achieved an accuracy around **0.50** or even lower. The `DummyClassifier` also scored **0.50**, which suggests that many models performed no better than random guessing, or simply predicted the majority class, indicating their inability to learn meaningful patterns from the provided features.\n",
        "\n",
        "*   **Linear Models (e.g., LogisticRegression, LinearSVC, Perceptron, SGDClassifier, RidgeClassifier):** These models assume a linear relationship between features and the target variable. Given the dynamic nature of shake detection from accelerometer data, the distinction between 'rest' and 'shake' might not be linearly separable in the 3D acceleration feature space (`ax`, `ay`, `az`). This limitation explains their significantly lower performance compared to tree-based ensembles.\n",
        "*   **Simple Tree Models (e.g., DecisionTreeClassifier, ExtraTreeClassifier):** While tree-based, a single decision tree or very shallow ensembles might not be powerful enough to capture the complex decision boundaries required. Their performance being close to random suggests they either overfit or underfit due to the limited feature set and potentially complex underlying signal.\n",
        "*   **Nearest Neighbors based models (e.g., KNeighborsClassifier, NearestCentroid):** These models rely on distance metrics. The effectiveness of such models can be highly dependent on the scale and distribution of features, and in this context, they struggled to achieve high accuracy.\n",
        "*   **Naive Bayes (BernoulliNB, GaussianNB):** These models make strong independence assumptions about features, which might not hold true for accelerometer data where `ax`, `ay`, and `az` can be correlated during motion. Their low accuracy (0.47 and 0.33 respectively) reflects this.\n",
        "\n",
        "**3. Suitability for Shake Detection:**\n",
        "\n",
        "*   **Highly Suitable:** `LGBMClassifier` and `XGBClassifier` are highly suitable for this shake detection problem. Their high accuracy (0.91 and 0.82) indicates they can reliably classify 'shake' vs. 'rest' states using the acceleration data. Their ensemble learning approach is well-suited for handling the complexity of motion sensor data.\n",
        "*   **Unsuitable:** Most other models, especially those performing near or below 0.50 accuracy (like `LogisticRegression`, `LinearSVC`, `DecisionTreeClassifier`, `GaussianNB`, etc.), are **unsuitable** for this specific shake detection task with the current feature set. Their inherent limitations in capturing non-linear patterns or dealing with the specific characteristics of the sensor data lead to poor predictive performance. Even the `LogisticRegression` model, which was manually explored earlier, showed a similar mediocre performance (0.31-0.50) when only using acceleration features, corroborating LazyPredict's findings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c956955d"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "The suitability of different machine learning models for shake detection using sensor data, specifically acceleration features, was evaluated. `LGBMClassifier` and `XGBClassifier` were found to be highly suitable, achieving accuracies of 0.91 and 0.82 respectively. Most other models, including linear models, simple tree models, and Naive Bayes classifiers, performed poorly (accuracies often around 0.50 or lower), indicating their unsuitability for this specific problem with the current feature set.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   The `lazypredict` library, version `0.2.16`, was successfully installed for automated machine learning model comparison.\n",
        "*   `LGBMClassifier` was the top-performing model, achieving an Accuracy, Balanced Accuracy, ROC AUC, and F1 Score of **0.91** with a training time of 0.09 seconds.\n",
        "*   `XGBClassifier` was the second-best model, showing strong performance with an Accuracy, Balanced Accuracy, and ROC AUC between **0.82-0.83** with a training time of 0.11 seconds.\n",
        "*   Many other classification models, such as `LogisticRegression`, `LinearSVC`, `Perceptron`, `DecisionTreeClassifier`, `GaussianNB`, and `DummyClassifier`, performed significantly worse, with accuracies often around **0.50** or even lower (down to 0.26).\n",
        "*   The superior performance of `LGBMClassifier` and `XGBClassifier` is attributed to their ensemble nature and ability to model complex, non-linear relationships inherent in sensor data.\n",
        "*   Linear models struggled due to the likely non-linear relationship between acceleration data and shake states, while Naive Bayes models performed poorly, possibly due to violated assumptions of feature independence among accelerometer readings.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   Focus further development on `LGBMClassifier` and `XGBClassifier` given their robust performance and efficiency, potentially exploring hyperparameter tuning to optimize them for deployment.\n",
        "*   Investigate feature engineering (e.g., statistical features over time windows, frequency domain features) from the raw accelerometer data to potentially improve the performance of currently underperforming models or further enhance the top models.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "general",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}